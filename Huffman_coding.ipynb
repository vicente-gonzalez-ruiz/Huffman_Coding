{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Huffman coding](https://en.wikipedia.org/wiki/Huffman_coding) [[Huffman, 1952]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=huffman+method+codes+1952&btnG=)\n",
    " \n",
    "* (Absolute) Optimal performance (in average, better than Shannon-Fano) when a integer\n",
    "  number of bits is assigned to each symbol.\n",
    "* Huffman-based VLC codecs build a binary tree where the symbols are stored\n",
    "  in the leafs and the distance of each symbol to the root of the tree\n",
    "  is $\\lceil\\log_2(p(s))\\rceil$.\n",
    "* After label each binary branch in the tree, the Huffman\n",
    "  code-word for the symbol $s$ is the sequence of bits (labels) that\n",
    "  we must use to travel from the root to the $s$-leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Building Huffman trees\n",
    "\n",
    "1. Create a list of nodes. Each node stores a symbol and its\n",
    "   probability.\n",
    "2. While the number of nodes in the list > 1:\n",
    "    1. Extract from the list the 2 nodes with the lowest probability.\n",
    "    2. Insert in the list a new node (that is the root of a binary\n",
    "       tree) whose probability is the sum of the probability of its\n",
    "       leafs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "<img src=\"data/huffman_ejemplo.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Encoder\n",
    "TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decoder\n",
    "TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limits\n",
    "\n",
    "* Any Huffman code satisfies that\n",
    "  \\begin{equation}\n",
    "    l\\big(c(s)\\big) = \\lceil I(s)\\rceil, \\tag{Eq:Huffman}\n",
    "  \\end{equation}\n",
    "  where $l\\big(c(s)\\big)$ is the length of the code-word assigned to\n",
    "  the symbol $s$. This implies that, with each encoded symbol, up to 1 bit of\n",
    "  redundant data can be introduced (think about a very frequent -- high probability -- symbol).\n",
    "  \n",
    "* This is a problem that grows when the size of the alphabet is\n",
    "  small. In the extreme case, for binary source alphabets, the Huffman\n",
    "  coding does not change the length of the original representation."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
